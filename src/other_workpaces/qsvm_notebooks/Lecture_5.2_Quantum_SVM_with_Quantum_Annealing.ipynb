{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QSVM_QA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAvdTyC91QSg"
      },
      "source": [
        "# Quantum SVM with Quantum Annealing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wM6F62vekss"
      },
      "source": [
        "In this tutorial, a quantum version of the Support Vector Machine (SVM) algorithm based on Quantum Annealing (QA) is presented."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ9bADrPZDOO"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9be-WEecfjRx"
      },
      "source": [
        "Before starting, some basic theoretical concepts are introduced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjZU2pwofo0U"
      },
      "source": [
        "### Support Vector Machine (SVM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeZQwLMsn1ny"
      },
      "source": [
        "Given a training set $T=\\left\\{\\left(\\textbf{x}_{n}, y_{n}\\right): n=0, \\ldots, N-1\\right\\}$, where $\\textbf{x}_{n} \\in \\mathbb{R}^{d}$ are the feature vectors and $y_n \\in \\{-1,1\\}$ are the binary labels, the conventional dual formulation of a SVM can be defined as the following quadratic programming problem: \n",
        "$$\n",
        "\\min_{\\pmb{\\alpha}}L(\\pmb{\\alpha})=\\frac{1}{2} \\sum_{n m} \\alpha_{n} \\alpha_{m} y_{n} y_{m} k\\left(\\mathbf{x}_{n}, \\mathbf{x}_{m}\\right)-\\sum_{n} \\alpha_{n},\n",
        "$$\n",
        "subject to the constraints\n",
        "$$\n",
        "\\begin{split}\n",
        "\\quad 0 \\leq \\alpha_{n} \\leq C  \\> \\> \\text { ; } \\> \\> \\sum_{n} \\alpha_{n} y_{n}=0,\n",
        "\\end{split}\n",
        "$$\n",
        "where $\\pmb{\\alpha}=\\{\\alpha_n:n=0,...,N-1\\}$ are the variables of the optimization problem (the Lagrange multipliers), $k(\\mathbf{x}_n, \\mathbf{x}_m)$ is the kernel function and $C$ is the regularization parameter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1jrwa-1oZmt"
      },
      "source": [
        "### Quadratic Unconstrained Binary Optimization (QUBO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSYAljIa5RY1"
      },
      "source": [
        "A QUBO problem is an optimization problem with the following properties:\n",
        "* _Quadratic_: the energy function $E$ (also called cost function) is a quadratic polynomial;\n",
        "* _Unconstrained_: no constraints are required;\n",
        "* _Binary_: the unknowns are a set of $n$ binary variables $x \\in \\{ 0,1 \\}^n$.\n",
        "\n",
        "It can be represented by a weighted graph $G$ where the vertices $V(G)$ are the variables and the edges $E(G)$ are the weights associated to each variables product. \n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1l9cZmaN7DFrQAsqkdmhuNQkC2qrlWRqx\"\n",
        "  width=\"30%\"/>\n",
        "</p>\n",
        "\n",
        "The mathematical formulation of the QUBO problem is:\n",
        "\n",
        "$$\n",
        "\\min_{x \\in \\{0,1 \\}^n} \\sum_{(ij) \\in E(G)} Q_{ij}x_i x_j + \\sum_{i \\in V(G)}Q_{ii}x_i = \\min_{x \\in \\{0,1 \\}^n}  x^\\top Q x\n",
        "$$\n",
        "\n",
        "where the graph $G$ is defined by the QUBO matrix $Q$ of dimensions $n\\times n$ (also called adjacency matrix). For example, the QUBO matrix associated with the graph above is:\n",
        "\n",
        "$$\n",
        "Q=\\begin{bmatrix}\n",
        "0 & 3 & 0 & 7 & 8\\\\\n",
        "3 & 0 & 1 & 4 & 0\\\\\n",
        "0 & 1 & 0 & 2 & 0\\\\\n",
        "7 & 4 & 2 & 0 & 3\\\\\n",
        "8 & 0 & 0 & 3 & 0\\\\\n",
        "\\end{bmatrix}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1VhUvPKJOX0"
      },
      "source": [
        "### Minor Embedding\n",
        "_D-Wave Advantage_ is a quantum computing machine based on quantum annealing, with more than 5000 qubits and more than 35000 couplers (connections between couples of qubits). Here is a representation of the Pegasus qubit architecture of Advantage.\n",
        "\n",
        "\n",
        "<figure> \n",
        "  <p align=\"center\">\n",
        "    <img src=\"https://drive.google.com/uc?export=view&id=1uGqhnHDV54dPSG6Tp7oTiJMyQgkGKlzl\" width=\"40%\"/>\n",
        "    <figcaption>\n",
        "    <p align=\"center\">\n",
        "        Source: D-Wave Documentation\n",
        "    </p>\n",
        "    </figcaption>\n",
        "  </p>\n",
        "</figure>\n",
        "\n",
        "A problem can be submitted to a D-Wave quantum annealer in the form of a QUBO problem. To do so, a process called _minor embedding_ is needed. The binary variables of the problem are mapped to physical qubits, with the requirement that linked binary variables correspond to linked physical qubits.\n",
        "\n",
        "<figure> \n",
        "  <p align=\"center\">\n",
        "    <img src=\"https://drive.google.com/uc?export=view&id=1_2dEm0UD-IxDDL2rDjghqsdyEsT7OxcI\" width=\"60%\"/>\n",
        "    <figcaption>\n",
        "    <p align=\"center\">\n",
        "        Source: D-Wave Systems\n",
        "    </p>\n",
        "    </figcaption>\n",
        "  </p>\n",
        "</figure>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACGDX5uKnPyM"
      },
      "source": [
        "## Initial Steps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubAtQaSRM2Qm"
      },
      "source": [
        "### Library Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvK9X_wgg3_p"
      },
      "source": [
        "Fortunately, in Colab we have access to a cloud environment where we can freely access computing machines and easily run Python codes without initial configuration. All we need to do is import the needed libraries. In our case, we will just have to manually install the libraries for implementing quantum algorithms and submitting tasks to D-Wave quantum annealers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vImqY_WhqoOy"
      },
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    !pip install dwave-ocean-sdk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOl-pi3_NHZa"
      },
      "source": [
        "### Account Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G2piaNPL163"
      },
      "source": [
        "A configuration file must be created in order to set up the solver. Launch the following interactive command and complete the fields as indicated in the image. The authentication token can be found by signing into your D-Wave account on https://cloud.dwavesys.com/leap/.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=16ajHppOFefGtgdRDtAWlcYSSC8PbNUHo\" width=\"60%\"/>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuVpWq_72Lsf"
      },
      "source": [
        "!dwave config create"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaYDW9SDDB4W"
      },
      "source": [
        "Check the correctness of the configuration:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af50Xw7eH3C_"
      },
      "source": [
        "!dwave ping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QiOznDT6o2E"
      },
      "source": [
        "### Library Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC5uMu2fgZxv"
      },
      "source": [
        "We import and rename the libraries we will be using during the tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8HQVC0R6oj4"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import gc\n",
        "import json\n",
        "import glob\n",
        "import shutil\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import dimod\n",
        "import numpy.lib.recfunctions as rfn\n",
        "from dwave.system.samplers import DWaveSampler\n",
        "from dwave.system.composites import EmbeddingComposite\n",
        "from dwave.system.composites import LazyFixedEmbeddingComposite\n",
        "from dimod import BinaryQuadraticModel"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAW4R7E_MxGf"
      },
      "source": [
        "## Quantum SVM Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkEWiGzAhkE0"
      },
      "source": [
        "Now we are ready to introduce our Quantum SVM algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPQCfPQIlGSW"
      },
      "source": [
        "### Mathematical Formulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-QSQQVFo_mG"
      },
      "source": [
        "The starting point of our algorithm is the dual formulation of the SVM (see **Introduction**). In order to leverage quantum annealing, we have to follow this golden rule:\n",
        "\n",
        "> **The optimization problem must be reframed as a QUBO problem.**\n",
        "\n",
        "Let's compare the classic SVM with the properties of QUBO:\n",
        "* _Quadratic_: the energy function is a quadratic polynomial w.r.t. the unknowns $\\alpha_{n}$  ✔️\n",
        "* _Unconstrained_: two constraints are required ❌\n",
        "* _Binary_: the unknowns $\\alpha_{n}$ are real, non-negative values ❌"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA4_hnL6nI7G"
      },
      "source": [
        "Let's start from the _binary_ requirement. A strategy is to discretize the $\\alpha_n$ solution space and to use binary variables to encode each discretized value of $\\alpha_{n}$ using the following encoding:\n",
        "\n",
        "$$\n",
        "\\alpha_{n}=\\sum_{k=0}^{K-1} B^{k-E} a_{K n+k},\n",
        "$$\n",
        "\n",
        "where $a_{K n+k} \\in\\{0,1\\}$ are binary variables, $K$ is the number of binary variables used to encode $\\alpha_{n}$, $B\\geq 0$ is the base, and $E \\geq 0$ is a parameter that allows for negative exponents.\n",
        "\n",
        "This encoding already solves the first SVM constraint, since it bounds the possible values of $\\alpha_n$.\n",
        "Regarding the second constraint, we can directly add it into the energy function $E$ and a squared penalty term, multiplied by $\\xi/2$.\n",
        "\n",
        "With these assumptions, the energy function can be written as\n",
        "$$\n",
        "E=\\sum_{n, m=0}^{N-1} \\sum_{k, j=0}^{K-1} a_{K n+k} \\widetilde{Q}_{K n+k, K m+j} a_{K m+j},\n",
        "$$\n",
        "\n",
        "where $\\widetilde{Q}$ is the QUBO matrix of size $K N \\times K N$ given by \n",
        "\n",
        "$$\n",
        "\\widetilde{Q}_{K n+k, K m+j} =\\frac{1}{2} B^{k+j-2E} y_{n} y_{m}\\left(k\\left(\\mathbf{x}_{n}, \\mathbf{x}_{m}\\right)+\\xi\\right) -\\delta_{n m} \\delta_{k j} B^{k-E}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iVpfKzNXHaj"
      },
      "source": [
        "### Functions Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es8u1uazXTT3"
      },
      "source": [
        "For the sake of clarity and conciseness, we split the algorithm in functions, each one performing a specific task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxr1dqEkAPwB"
      },
      "source": [
        "* The function ``decode`` converts a vector of binary values to a vector real values $\\alpha_n$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FaWqEdKAQdB"
      },
      "source": [
        "def decode(binary, B=2, K=3, E=0):\n",
        "    N = len(binary) // K  # Number of real variables we have to decode (alphas)\n",
        "    Bvec = float(B) ** (np.arange(K)-E)\n",
        "    return np.fromiter(binary,float).reshape(N,K) @ Bvec"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqcWgniJKFW7"
      },
      "source": [
        "* The function ``kernel`` implements the kernel function. The Gaussian kernel is selected:\n",
        "$$\n",
        "k\\left(\\mathbf{x}_{n}, \\mathbf{x}_{m}\\right) = e^{-\\gamma ||\\mathbf{x}_{n}- \\mathbf{x}_{m}||^2}\n",
        "$$\n",
        "\n",
        "``xn`` has shape ``(N,D)`` and ``xm`` has shape ``(M,D)``. The result is a kernel matrix of shape ``(N,M)``. If ``gamma=-1``, a linear kernel is selected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56sjrtipKFpO"
      },
      "source": [
        "def kernel(xn, xm, gamma=-1):\n",
        "    if gamma == -1:\n",
        "        return xn @ xm.T\n",
        "    xn = np.atleast_2d(xn)\n",
        "    xm = np.atleast_2d(xm)\n",
        "    return np.exp(-gamma * np.sum((xn[:,None] - xm[None,:])**2, axis=-1))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Xeeyc3uWVXH"
      },
      "source": [
        "* The function ``gen_svm_qubos`` generates the QUBO matrix $Q$ according to its definition.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq2UoYUmZyap"
      },
      "source": [
        "def gen_svm_qubos(data,label,B,K,xi,gamma,E,path):\n",
        "\n",
        "    N = len(data)\n",
        "    \n",
        "    if not os.path.isfile(path+'Q.npy'):\n",
        "      Q = ## MISSING CODE HERE: Initialize QUBO matrix to zero\n",
        "    \n",
        "      print(f'Creating the QUBO of size {Q.shape}')\n",
        "      for n in range(N):\n",
        "          for m in range(N):\n",
        "              for k in range(K):\n",
        "                  for j in range(K):\n",
        "                      Q[K*n+k,K*m+j] = ## MISSING CODE HERE: QUBO matrix\n",
        "                      if n == m and k == j:\n",
        "                          Q[K*n+k,K*m+j] += - B**(k-E)\n",
        "\n",
        "\n",
        "      Q = np.triu(Q) + np.tril(Q,-1).T\n",
        "    else:\n",
        "      Q = np.load(path+'Q.npy')\n",
        "    print(f'Extracting nodes and couplers')\n",
        "    qubo_nodes = np.asarray([[n, n, Q[n,n]] for n in range(len(Q))])\n",
        "    qubo_couplers = np.asarray([[n, m, Q[n,m]] for n in range(len(Q)) for m in range(n+1,len(Q)) if not np.isclose(Q[n,m],0)])\n",
        "    qubo_couplers = qubo_couplers[np.argsort(-np.abs(qubo_couplers[:,2]))]\n",
        "\n",
        "\n",
        "    print(f'Saving {len(qubo_nodes)} nodes and {len(qubo_couplers)} couplers for {path}')\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    np.save(path+'Q.npy', Q)\n",
        "    np.savetxt(path+'qubo_nodes.dat', qubo_nodes, fmt='%g', delimiter='\\t')\n",
        "    np.savetxt(path+'qubo_couplers.dat', qubo_couplers, fmt='%g', delimiter='\\t')\n",
        "    \n",
        "    return\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oar6gyb3QY8Q"
      },
      "source": [
        "The function ``dwave_run_embedding`` submits the QUBO problem to the selected quantum annealer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bRgn1ppQZkY"
      },
      "source": [
        "def dwave_run_embedding(data,label,path_in,annealing_times,chain_strengths,em_id,solver='Advantage_system1.1'):\n",
        "    \n",
        "    MAXRESULTS = 20\n",
        "    match = re.search('run_([^/]*)_B=(.*)_K=(.*)_xi=(.*)_E=(.*)_gamma=([^/]*)', path_in) \n",
        "\n",
        "    data_key = match.group(1)\n",
        "    B = int(match.group(2))\n",
        "    K = int(match.group(3))\n",
        "    xi = float(match.group(4))\n",
        "    gamma = float(match.group(6))\n",
        "    E = int(match.group(5))\n",
        "\n",
        "    path = path_in+ ('/' if path_in[-1] != '/' else '')\n",
        "    qubo_couplers = np.loadtxt(path+'qubo_couplers.dat')\n",
        "    qubo_nodes = np.loadtxt(path+'qubo_nodes.dat')\n",
        "    qubo_nodes = np.array([[i,i,(qubo_nodes[qubo_nodes[:,0]==i,2][0] if i in qubo_nodes[:,0] else 0.)] for i in np.arange(np.concatenate((qubo_nodes,qubo_couplers))[:,[0,1]].max()+1)])  # to make sure every (i,i) occurs in the qubo in increasing order such that the variable order in BinaryQuadraticModel is consistent (see locate wrongenergies-* github issue)\n",
        "    maxcouplers = len(qubo_couplers)\n",
        "\n",
        "    if not 'train' in data_key:\n",
        "        raise Exception(f'careful: datakey={data_key} => youre trying to train on a validation / test set!')\n",
        "\n",
        "    couplerslist = [min(7500,maxcouplers)]\n",
        "    for trycouplers in [5000, 2500, 2000, 1800, 1600, 1400, 1200, 1000, 500]:\n",
        "        if maxcouplers > trycouplers:\n",
        "            couplerslist += [trycouplers]\n",
        "\n",
        "\n",
        "    sampler = LazyFixedEmbeddingComposite(DWaveSampler(solver=solver))\n",
        "    for n in range(0,len(chain_strengths)):\n",
        "        for m in range(0,len(annealing_times)):\n",
        "            if n==0 and m==0:\n",
        "                for couplers in couplerslist:\n",
        "                    Q = { (q[0], q[1]): q[2] for q in np.vstack((qubo_nodes, qubo_couplers[:couplers])) }\n",
        "                    maxstrength=np.max( np.abs( list( Q.values() ) ) )\n",
        "                    pathsub = path + f'result_couplers={couplers}/'\n",
        "                    os.makedirs(pathsub, exist_ok=True)\n",
        "                    embedding_file_name=pathsub+f'embedding_id{em_id}'\n",
        "                    if os.path.isfile(embedding_file_name):\n",
        "                        embedding_file=open(embedding_file_name,'r')\n",
        "                        embedding_data=eval(embedding_file.read())\n",
        "                        embedding_file.close()\n",
        "                        sampler._fix_embedding(embedding_data)\n",
        "                    print(f'running {pathsub} with {len(qubo_nodes)} nodes and {couplers} couplers for embedding {em_id}')\n",
        "    \n",
        "                    ordering = np.array(list(BinaryQuadraticModel.from_qubo(Q)))\n",
        "                    if not (ordering == np.arange(len(ordering),dtype=ordering.dtype)).all():\n",
        "                        print(f'WARNING: variables are not correctly ordered! path={path} ordering={ordering}')\n",
        "\n",
        "                    try:\n",
        "                        print(f'Running chain strength {chain_strengths[n]} and annealing time {annealing_times[m]}\\n')\n",
        "                        response = sampler.sample_qubo(Q, num_reads=5000, annealing_time=annealing_times[0], chain_strength=chain_strengths[0]*maxstrength)\n",
        "                        if not os.path.isfile(embedding_file_name):\n",
        "                            embedding_file=open(embedding_file_name,'w')\n",
        "                            print('Embedding found. Saving...')\n",
        "                            embedding_file.write(repr(sampler.embedding))\n",
        "                            embedding_file.close()\n",
        "            \n",
        "                    except ValueError as v:\n",
        "                        print(f' -- no embedding found, removing {pathsub} and trying less couplers')\n",
        "                        shutil.rmtree(pathsub)\n",
        "                        sampler = LazyFixedEmbeddingComposite(DWaveSampler(solver=solver))\n",
        "                        continue\n",
        "                    break\n",
        "            else:\n",
        "                print(f'Running chain strength {chain_strengths[n]} and annealing time {annealing_times[m]}')\n",
        "                response = sampler.sample_qubo(Q, num_reads=5000, annealing_time=annealing_times[m], chain_strength=chain_strengths[n]*maxstrength)\n",
        "\n",
        "            pathsub_ext=pathsub+f'embedding{em_id}_rcs{chain_strengths[n]}_ta{annealing_times[m]}_'\n",
        "            save_json(pathsub_ext+'info.json', response.info)\n",
        "\n",
        "            samples = np.array([''.join(map(str,sample)) for sample in response.record['sample']]) \n",
        "            unique_samples, unique_idx, unique_counts = np.unique(samples, return_index=True, return_counts=True)\n",
        "            unique_records = response.record[unique_idx]\n",
        "            result = rfn.merge_arrays((unique_samples, unique_records['energy'], unique_counts, unique_records['chain_break_fraction'])) \n",
        "            result = result[np.argsort(result['f1'])]\n",
        "            np.savetxt(pathsub_ext+'result.dat', result[:MAXRESULTS], fmt='%s', delimiter='\\t', header='\\t'.join(response.record.dtype.names), comments='')\n",
        "\n",
        "            alphas = np.array([decode(sample,B,K,E) for sample in result['f0'][:MAXRESULTS]])\n",
        "            np.save(pathsub_ext+f'alphas.npy', alphas)\n",
        "            gc.collect()\n",
        "    \n",
        "    return pathsub\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkDE2rxU6h4Q"
      },
      "source": [
        "* Some additional functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2GtULMv5bUn"
      },
      "source": [
        "def plot_qa_svm(alphas, data, label, gamma, B, K, xylim=[-0.7, 1.7], notitle=False, filled=False,\n",
        "                plot_support=True):\n",
        "    C = (B ** np.arange(K)).sum()\n",
        "    b = eval_offset_avg(alphas, data, label, gamma, C)\n",
        "    result = np.copysign(1, eval_classifier(data, alphas, data, label, gamma, b))\n",
        "\n",
        "    xsample = np.arange(xylim[0], xylim[1] + .01, .05)\n",
        "    x1grid, x2grid = np.meshgrid(xsample, xsample)\n",
        "    X = np.vstack((x1grid.ravel(), x2grid.ravel())).T  # ...xD for kernel contraction\n",
        "    FX = eval_classifier(X, alphas, data, label, gamma, b).reshape(len(xsample), len(xsample))\n",
        "\n",
        "    plt.pcolor(x1grid, x2grid, FX, cmap='coolwarm')\n",
        "    plt.contour(x1grid, x2grid, FX, [0.], linewidths=3, colors='black')\n",
        "\n",
        "    if not filled:\n",
        "        plt.scatter(data[result == 1][:, 0], data[result == 1][:, 1], c='r', marker=(8, 2, 0), linewidth=0.5)\n",
        "        plt.scatter(data[result != 1][:, 0], data[result != 1][:, 1], c='b', marker='+', linewidth=1)\n",
        "        plt.scatter(data[label == 1][:, 0], data[label == 1][:, 1], edgecolors='r', marker='s', linewidth=0.5,\n",
        "                    facecolors='none')\n",
        "        plt.scatter(data[label != 1][:, 0], data[label != 1][:, 1], edgecolors='b', marker='o', linewidth=1,\n",
        "                    facecolors='none')\n",
        "    else:\n",
        "        plt.scatter(data[label == 1][:, 0], data[label == 1][:, 1], edgecolors='r', marker='s', linewidth=1,\n",
        "                    facecolors='r')\n",
        "        plt.scatter(data[label != 1][:, 0], data[label != 1][:, 1], edgecolors='b', marker='o', linewidth=1,\n",
        "                    facecolors='b')\n",
        "\n",
        "    # plot support vectors\n",
        "    if plot_support:\n",
        "        support_vectors = data[np.nonzero(alphas)[0]]\n",
        "        plt.scatter(support_vectors[:, 0], support_vectors[:, 1], edgecolors='green', facecolors='none', s=300,\n",
        "                    linewidth=1)\n",
        "\n",
        "    if not notitle:\n",
        "        support_vectors = data[np.nonzero(alphas)[0]]\n",
        "        plt.title(\n",
        "            str(len(support_vectors)) + ' SVs, ' + str(round(((result == label).sum() / len(label)), 2)) + ' accuracy')\n",
        "\n",
        "    plt.xlim(*xylim)\n",
        "    plt.ylim(*xylim)\n",
        "\n",
        "def eval_offset_avg(alphas, data, label, gamma, C, useavgforb=True):\n",
        "    cross = eval_classifier(data, alphas, data, label,\n",
        "                            gamma)\n",
        "    if useavgforb:\n",
        "        return np.sum(alphas * (C - alphas) * (label - cross)) / np.sum(alphas * (C - alphas))\n",
        "    else:\n",
        "        if np.isclose(np.sum(alphas * (C - alphas)), 0):\n",
        "            print('no support vectors found, discarding this classifer')\n",
        "            return np.nan\n",
        "        bcandidates = [np.sum(alphas * (C - alphas) * (label - cross)) / np.sum(\n",
        "            alphas * (C - alphas))]\n",
        "        crosssorted = np.sort(cross)\n",
        "        crosscandidates = -(crosssorted[1:] + crosssorted[\n",
        "                                              :-1]) / 2\n",
        "        bcandidates += sorted(crosscandidates,\n",
        "                              key=lambda x: abs(x - bcandidates[0]))\n",
        "        bnumcorrect = [(label == np.sign(cross + b)).sum() for b in bcandidates]\n",
        "        return bcandidates[np.argmax(bnumcorrect)]\n",
        "\n",
        "def save_json(filename, var):\n",
        "    with open(filename,'w') as f:\n",
        "        f.write(str(json.dumps(var, indent=4, sort_keys=True, separators=(',', ': '), ensure_ascii=False)))\n",
        "\n",
        "def eval_classifier(x, alphas, data, label, gamma,\n",
        "                    b=0):\n",
        "    return np.sum((alphas * label)[:, None] * kernel(data, x, gamma), axis=0) + b\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0yQpIMRNzSq"
      },
      "source": [
        "### Dataset and Parameters Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Nc8jsi4OARd"
      },
      "source": [
        "We test our binary classification algorithm on a simple dataset consisting of $N=40$ samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwewwtYTOTaB"
      },
      "source": [
        "X_train = np.array([\n",
        "       [ 0.0401,  0.1415],\n",
        "       [-0.1211, -0.0228],\n",
        "       [-0.1688,  0.2911],\n",
        "       [ 0.2293,  0.7856],\n",
        "       [-1.0831, -0.1049],\n",
        "       [ 0.1626, -1.0458],\n",
        "       [ 0.311 , -0.1032],\n",
        "       [-0.9376, -0.2677],\n",
        "       [ 0.7176, -0.7998],\n",
        "       [-0.0197,  0.3323],\n",
        "       [-0.1306,  0.1053],\n",
        "       [ 0.0811, -0.1263],\n",
        "       [ 0.3391,  0.1625],\n",
        "       [ 0.6602,  0.0843],\n",
        "       [-0.1588,  0.1835],\n",
        "       [-0.3887,  0.2282],\n",
        "       [ 0.2555,  0.0709],\n",
        "       [ 0.1717, -0.9481],\n",
        "       [-0.0288, -0.1503],\n",
        "       [-0.7354,  0.5788],\n",
        "       [-0.6483, -1.2539],\n",
        "       [ 0.1448,  1.0718],\n",
        "       [ 0.803 , -0.7706],\n",
        "       [-0.1384, -0.9474],\n",
        "       [-0.0025,  0.0779],\n",
        "       [-0.686 ,  0.9516],\n",
        "       [ 0.1013, -0.5189],\n",
        "       [ 0.8678,  0.0948],\n",
        "       [-0.0021, -0.082 ],\n",
        "       [-1.0192, -0.3854],\n",
        "       [ 0.1661, -0.1268],\n",
        "       [ 0.2193,  0.0973],\n",
        "       [-0.1468,  1.0086],\n",
        "       [-0.0195,  0.503 ],\n",
        "       [ 0.0475,  0.3345],\n",
        "       [ 0.7212, -0.1479],\n",
        "       [-0.5998,  0.5036],\n",
        "       [-0.1889, -0.0499],\n",
        "       [ 0.9087,  0.525 ],\n",
        "       [ 0.5112, -0.4113]])\n",
        "Y_train = np.array(\n",
        "      [ 1.,  1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,\n",
        "       -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1., -1., -1.,  1., -1.,\n",
        "        1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,\n",
        "       -1.])\n",
        "\n",
        "plt.figure(0)\n",
        "plt.title('Training set')\n",
        "plt.xlim(-2, 2)\n",
        "plt.ylim(-2, 2)\n",
        "plot = plt.scatter(X_train[:, 0], X_train[:, 1], c=Y_train, s=50, cmap='autumn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-CC-j5CUAQr"
      },
      "source": [
        "Now we define the parameters of the algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wMwdacsOBNn"
      },
      "source": [
        "outputpath='output/run_train'\n",
        "maxalphas=20\n",
        "\n",
        "Bs=[2]\n",
        "Ks=[2]\n",
        "xis=[0]\n",
        "gammas=[5]\n",
        "Es=[0]\n",
        "annealing_times=[10]\n",
        "chain_strengths=[1]\n",
        "embeddings=[0]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBiHSMX-4dy8"
      },
      "source": [
        "### Problem Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJPkwUfFUzqa"
      },
      "source": [
        "Now we can launch the algorithm, once for every parameter combination."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYMj7lUgUFiJ"
      },
      "source": [
        "for B in Bs:\n",
        "    for K in Ks:\n",
        "        for gamma in gammas:\n",
        "            for xi in xis:\n",
        "                for E in Es:\n",
        "                    path=outputpath+f'_B={B}_K={K}_xi={xi}_E={E}_gamma={gamma}/'\n",
        "                    gen_svm_qubos(X_train,Y_train,B,K,xi,gamma,E,path)\n",
        "                    for i in embeddings:\n",
        "                        dwave_run_embedding(X_train,Y_train,path,annealing_times,chain_strengths,i)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bhwivBU5Nkp"
      },
      "source": [
        "for B in Bs:\n",
        "    for K in Ks:\n",
        "        for gamma in gammas:\n",
        "            for xi in xis:\n",
        "                for E in Es:\n",
        "                    dirs=glob.glob(outputpath+f'_B={B}_K={K}_xi={xi}_E={E}_gamma={gamma}/result_couplers=*')\n",
        "                    path=dirs[0]+'/'\n",
        "                    for emb in embeddings:\n",
        "                        for c in chain_strengths:\n",
        "                            for t in annealing_times:\n",
        "                              alphas=np.load(path+f'embedding{emb}_rcs{c}_ta{t}_alphas.npy')\n",
        "                              plot_qa_svm(alphas[0], X_train, Y_train, gamma, B,K, [-2,2], False, True, True)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}